***SUMMARY***

OVERVIEW: 
I used various techniques to train and evaluate a model based on loan risk. I used a dataset of historical lending activity from a peer-to-peer lending services company to build a model that can identify the creditworthiness of borrowers.  I have created a trained/tested model for this purpose.

DEFINITIONS:
Accuracy - represents the number of correctly classified data instances over the total number of data instances; "out of all the predictions we made, how many were true?”
Precision - metric that gives you the proportion of true positives to the amount of total positives that the model predicts. It answers the question “uut of all the positive predictions we made, how many were true?”
Recall - how good the model is at finding all the positives. Recall is also called true positive rate and answers the question “out of all the data points that should be predicted as true, how many did we correctly predict as true?”
‍F1 Score - a machine learning evaluation metric that measures a model’s accuracy. It combines the precision and recall scores of a model.

FINDINGS:  
The training & testing classification report outputs are as follows:

Training
  precision    recall  f1-score   support

           0       1.00      0.99      1.00     56277
           1       0.85      0.89      0.87      1875

    accuracy                           0.99     58152
   macro avg       0.92      0.94      0.93     58152
weighted avg       0.99      0.99      0.99     58152



Testing
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     18759
           1       0.87      0.89      0.88       625

    accuracy                           0.99     19384
   macro avg       0.94      0.94      0.94     19384
weighted avg       0.99      0.99      0.99     19384


RECOMMENDATION:
I would recommend this model.  Looking at the two classification reports for the training and test data, it looks as if model performance improved--albeit slightly--on the test data. We're still getting strong precision and recall on the test dataset; this is a good indication about how well the model is likely to perform in real life.
